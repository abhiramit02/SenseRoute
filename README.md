<img width="990" height="495" alt="image" src="https://github.com/user-attachments/assets/2450eeea-7c63-4678-8be7-164f9c2b8709" /># ğŸ§  SenseRoute â€“ AI-Powered Assistant for the Visually Impaired

**SenseRoute** is a smart, assistive virtual assistant built for the visually impaired, providing real-time environmental awareness, object recognition, voice interaction, and emergency alerting. It empowers users to navigate the world more independently and safely using AI and speech technologies.

---

## âœ¨ Key Features

- ğŸ¯ **Object Detection**: Detects and recognizes real-world objects using **YOLOv8** and **OpenCV**.
- ğŸ—£ï¸ **Text-to-Speech (TTS)**: Converts scene/object data into speech for auditory feedback.
- ğŸ“§ **Emergency Email Alerts**: Sends alerts with detected object descriptions and timestamps to a registered guardian via Gmail API.
- ğŸ”Š **Voice Command Integration**: Interacts via custom voice commands (e.g., "describe environment", "detect object", etc.).
- ğŸ“° **Location-Based News Updates**: Reads out the latest news headlines specific to the user's city.
- ğŸ“„ **OCR (Optical Character Recognition)**: Reads and speaks out text from images or captured scenes.
- ğŸ® **Maze Game**: A fun, brain-engaging game to enhance spatial thinking.
- ğŸ“· **Scene Description**: Captures and summarizes the full scene around the user.
- ğŸ”’ **Secure & Private**: Sensitive data like API tokens are excluded from the repository.

---

## ğŸ“¦ Tech Stack

- **Frontend**: React.js + Tailwind CSS + ShadCN UI + Framer Motion
- **Backend**: Python (Flask), Node.js (optional for API handling)
- **AI & Vision**: YOLOv8, OpenCV, Tesseract OCR
- **Voice**: gTTS / pyttsx3, SpeechRecognition
- **APIs Used**:
  - Gmail API (for alerts)
  - NewsAPI (for headlines)
  - OpenWeather API (optional for weather)
- **Other Tools**:
  - GitHub Actions (CI/CD)
  - Google OAuth (secure access)
  - Git Filter Repo (secret removal)

---

## ğŸ“‚ Folder Structure

```bash
SenseRoute/
â”œâ”€â”€ frontend/                # React UI
â”œâ”€â”€ assistant-backend/      # Python Flask backend
â”‚   â”œâ”€â”€ object_detection/   # YOLOv8 integration
â”‚   â”œâ”€â”€ ocr_module/         # Tesseract OCR logic
â”‚   â”œâ”€â”€ email_service/      # Gmail API handling
â”‚   â””â”€â”€ news_module/        # Location-based news reader
â”œâ”€â”€ .spyder-py3/            # Local config (ignored in Git)
â”œâ”€â”€ credentials.json        # (ignored) Google OAuth credentials
â”œâ”€â”€ token.json              # (ignored) Gmail API token
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

## **Maze Game â€“ For Visually Impaired Users**
![WhatsApp Image 2025-07-15 at 09 18 32_44a3c9ae](https://github.com/user-attachments/assets/0161feea-e978-4fed-bcc7-67e4deff41a3)

**ğŸ” What It Does**
This blind-accessible maze game empowers visually impaired users to explore and solve mazes using audio feedback and keyboard navigation.

**ğŸ§ Core Features**
âœ… Spatial Audio Guidance:

As the player (represented by a girl) gets closer to the goal (home), the volume of the goal sound increases.

If the player hits a wall, a sound is played from the direction of the wall, helping them understand spatial layout.

âœ… Keyboard-Based Navigation:

Use Shift to cycle through directions (â†‘ â†“ â† â†’).

Press Enter to confirm a move.

No mouse or screen interaction required.

âœ… Maze Generation:

New mazes are created using a depth-first search recursive algorithm.

This ensures random, solvable mazes each time.

âœ… Level Progression:

The game has 4 levels with increasing difficulty.

Players must complete 3 mazes per level to unlock the next stage (12 mazes total).

âœ… Replayability:

Click on New Maze at any time to generate a fresh challenge for the current level.

Previous Level allows replaying simpler levels.

**ğŸ¯ Goal**
Help the visually impaired user reach the destination (the house) using only audio cues and a simple keyboard interface. Each maze completed boosts confidence, spatial skills, and fun!


